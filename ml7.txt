import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

from sklearn.datasets import fetch_openml
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split

warnings.filterwarnings("ignore")  # Suppress warning messages

# -----------------------------
# Part 1: Linear Regression on Boston Housing
# -----------------------------
# Load Boston Housing dataset
boston = fetch_openml(name="boston", version=1, as_frame=True)
X_boston = boston.data
y_boston = boston.target

# Ensure all columns are numeric
X_boston = X_boston.apply(pd.to_numeric, errors='coerce')
y_boston = pd.to_numeric(y_boston, errors='coerce')

# Drop rows with any missing values
boston_data = pd.concat([X_boston, y_boston], axis=1).dropna()
X_boston = boston_data.iloc[:, :-1]
y_boston = boston_data.iloc[:, -1]

# Split dataset
X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_boston, y_boston, test_size=0.2, random_state=42)

# Train linear regression model
linear_model = LinearRegression()
linear_model.fit(X_train_b, y_train_b)
y_pred_b = linear_model.predict(X_test_b)

# Evaluate
print("----- Linear Regression: Boston Housing -----")
print(f"MSE: {mean_squared_error(y_test_b, y_pred_b):.2f}")
print(f"RMSE: {np.sqrt(mean_squared_error(y_test_b, y_pred_b)):.2f}")
print(f"R² Score: {r2_score(y_test_b, y_pred_b):.2f}")
print()

# Optional: Visualization of prediction vs actual
plt.scatter(y_test_b, y_pred_b, color='blue', alpha=0.6)
plt.plot([y_test_b.min(), y_test_b.max()], [y_test_b.min(), y_test_b.max()], color='red', linestyle='--')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Linear Regression: Actual vs Predicted (Boston Housing)")
plt.grid(True)
plt.show()

# -----------------------------
# Part 2: Polynomial Regression on Auto MPG
# -----------------------------
df = sns.load_dataset('mpg')
df = df.dropna()

# Ensure horsepower is numeric
df['horsepower'] = pd.to_numeric(df['horsepower'], errors='coerce')
df = df.dropna(subset=['horsepower'])

X_mpg = df[['horsepower']]
y_mpg = df['mpg']

# Split dataset
X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X_mpg, y_mpg, test_size=0.2, random_state=42)

# Polynomial regression (degree 2)
poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(X_train_m)
X_test_poly = poly.transform(X_test_m)

poly_model = LinearRegression()
poly_model.fit(X_train_poly, y_train_m)
y_pred_poly = poly_model.predict(X_test_poly)

# Evaluate
print("----- Polynomial Regression: Auto MPG (Degree 2) -----")
print(f"MSE: {mean_squared_error(y_test_m, y_pred_poly):.2f}")
print(f"RMSE: {np.sqrt(mean_squared_error(y_test_m, y_pred_poly)):.2f}")
print(f"R² Score: {r2_score(y_test_m, y_pred_poly):.2f}")
print()

# Plot Polynomial Regression results
X_range = np.linspace(X_mpg.min(), X_mpg.max(), 100).reshape(-1, 1)
X_range_poly = poly.transform(X_range)
y_range_pred = poly_model.predict(X_range_poly)

plt.scatter(X_mpg, y_mpg, color='green', label='Actual Data')
plt.plot(X_range, y_range_pred, color='red', label='Polynomial Fit (Degree 2)', linewidth=2)
plt.xlabel("Horsepower")
plt.ylabel("MPG")
plt.title("Polynomial Regression: Horsepower vs MPG")
plt.legend()
plt.grid(True)
plt.show()

